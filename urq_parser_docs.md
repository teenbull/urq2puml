## Алгоритм парсинга URQ файлов

1. **Определение кодировки** - проверяет UTF-8, затем CP1251 по первым 1024 байтам

2. **Предобработка контента** (`_prep_content`):
   - Удаляет комментарии (`/* */` и `;`)
   - Убирает переносы строк (`_`)
   - Разбивает `if/then/else` конструкции на отдельные строки  
   - Делит по амперсандам (`&`)

3. **Единый цикл парсинга** (`_parse_locations`):
   - Находит все regex-совпадения меток (`:`) одним вызовом
   - В одном проходе по совпадениям:
     * Вычисляет номера строк (накопительный подсчет `\n`)
     * Создает объект локации
     * Извлекает границы контента (до следующей метки)
     * Определяет дубликаты с помощью словаря `name_first_idx`
     * Извлекает описание из `pln`/`p` команд
     * Извлекает связи и устанавливает флаги в том же цикле

4. **Извлечение связей и флагов** (`_extract_links_and_flags`):
   - **Автосвязь** - если нет `end` или `goto`, связывает со следующей по индексу
   - **Обработка текста** - один проход по `TEXT_EXTRACTION` regex с дедупликацией
   - **Инлайн кнопки** - из уникальных `pln`/`p` текстов ищет `[[текст|цель]]`
   - **Явные команды** - `btn`, `goto`, `proc`
   - **Проверка циклов** - если цель = текущая локация

5. **Преобразование имен целей в ID** (`_resolve_target_ids`):
   - Создает предварительные словари `n_map` (основные) и `d_map` (дубликаты)
   - Обрабатывает автосвязи по индексам из `all_matches`
   - Ищет цели: самоссылки → основные → дубликаты → phantom
   - Помечает несуществующие цели как phantom

6. **Пометка концевых локаций** - те, из которых никто не ссылается (исключая дубликаты)

7. **Возврат результата** - массив локаций с преобразованными связями


## Формат результата парсинга

**Возвращает**: список объектов `Loc`

### `locs` - список объектов `Loc`:
```python
class Loc:
    id: str          # "0", "1", "2"... (порядковый номер)
    name: str        # "start", "room1", "ending"
    desc: str        # "Вы стоите в комнате" (из pln/p команд)
    line: int        # 15 (номер строки в файле)
    dup: bool        # True если дубликат метки
    cycle: bool      # True если есть самоссылка
    end: bool        # True если концевая (никто не ссылается)
    links: []        # [(target_id, target_name, type, label, is_phantom), ...]
```

### `links` - список кортежей:
```python
# (цель_id, имя_цели, тип_связи, текст_кнопки, фантом)
("1", "room2", "btn", "Идти направо", False)      # кнопка
("0", "start", "goto", "", False)                 # goto команда  
("2", "ending", "auto", "", False)                # автосвязь
(None, "unknown", "btn", "Куда-то", True)         # phantom-связь
```

**Типы связей**: `"btn"`, `"goto"`, `"proc"`, `"auto"`

**Phantom** = `True` если цель не существует в файле

## Особенности алгоритма

### Единый цикл парсинга
- Все основные операции выполняются в одном проходе по regex-совпадениям меток
- Эффективный подсчет номеров строк через накопительные переменные `cum_nl` и `last_nl_pos`
- Извлечение контента, создание локаций и обработка связей происходят последовательно
- Передача `all_matches` в `_extract_links_and_flags` для корректной проверки границ автосвязей

### Обработка автосвязей
- Временно сохраняются как индекс следующей локации `(next_idx, "auto", "")`
- При резолвинге проверяется `isinstance(link_data[0], int)` для определения автосвязи
- Заменяются на ID и имя следующей локации из массива `locs[idx]`
- Создаются только если нет команд `end` или `goto`

### Обработка дубликатов
- Отслеживание через словарь `name_first_idx` (имя → индекс первого вхождения)
- Дубликаты помечаются флагом `dup = True` сразу при обнаружении
- При резолвинге создаются предварительные словари:
  - `n_map` - основные локации (не дубликаты)  
  - `d_map` - первые вхождения дубликатов
- Концевые локации определяются исключая дубликаты (`not l_obj.dup`)

### Дедупликация обработки текста
- Используется `set processed_texts` для исключения повторной обработки одинаковых текстов
- Один проход по `TEXT_EXTRACTION` regex с условием `(t_type == 'pln' or not pln_found)`
- Инлайн кнопки извлекаются только из уникальных текстов
- Формат инлайн кнопок: `[[текст|цель]]` или `[[цель]]` (если текст = цель)

### Оптимизированный резолвинг целей
- Предварительное создание словарей `n_map` и `d_map` избегает множественного сканирования
- Порядок поиска: самоссылки → основные локации → дубликаты → phantom
- Отслеживание `found_dup_names` предотвращает перезапись в `d_map`

### Очистка текста
- Удаляются вложенные инлайн кнопки из описания и кнопок
- Кавычки заменяются на `''`
- Упрощенная логика для `cl_label` в кнопках (пустые строки vs строки из пробелов)

## Дополнительная информация

### Номера строк
Номер строки локации вычисляется эффективно через накопительный подсчет:
```python
seg_nl = content.count('\n', last_nl_pos, m.start())  # Сегментарный подсчет новых строк
cum_nl += seg_nl                                       # Накопительная сумма 
line_num = cum_nl + 1                                  # Номер строки (с 1)
last_nl_pos = m.start()                                # Обновляем позицию для следующей итерации
```
Используется для вывода предупреждений о дубликатах:
```python
self._add_warning(f"Найден дубликат метки: '{name}' на строке {line_num}")
```

### Предупреждения
Парсер генерирует предупреждения для:
- Отсутствующих файлов
- Проблем с кодировкой
- Отсутствия меток в файле
- Дубликатов меток
- Пустых целей в командах